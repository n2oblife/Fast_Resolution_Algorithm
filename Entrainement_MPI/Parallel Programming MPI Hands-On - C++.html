<!DOCTYPE html>
<html data-darkreader-mode="dynamic" data-darkreader-scheme="dark" lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><style class="darkreader darkreader--fallback" media="screen"></style><style class="darkreader darkreader--text" media="screen"></style><style class="darkreader darkreader--invert" media="screen">.jfk-bubble.gtx-bubble, .captcheck_answer_label > input + img, span#closed_text > img[src^="https://www.gstatic.com/images/branding/googlelogo"], span[data-href^="https://www.hcaptcha.com/"] > #icon, #bit-notification-bar-iframe, ::-webkit-calendar-picker-indicator {
    filter: invert(100%) hue-rotate(180deg) contrast(90%) !important;
}</style><style class="darkreader darkreader--inline" media="screen">[data-darkreader-inline-bgcolor] {
  background-color: var(--darkreader-inline-bgcolor) !important;
}
[data-darkreader-inline-bgimage] {
  background-image: var(--darkreader-inline-bgimage) !important;
}
[data-darkreader-inline-border] {
  border-color: var(--darkreader-inline-border) !important;
}
[data-darkreader-inline-border-bottom] {
  border-bottom-color: var(--darkreader-inline-border-bottom) !important;
}
[data-darkreader-inline-border-left] {
  border-left-color: var(--darkreader-inline-border-left) !important;
}
[data-darkreader-inline-border-right] {
  border-right-color: var(--darkreader-inline-border-right) !important;
}
[data-darkreader-inline-border-top] {
  border-top-color: var(--darkreader-inline-border-top) !important;
}
[data-darkreader-inline-boxshadow] {
  box-shadow: var(--darkreader-inline-boxshadow) !important;
}
[data-darkreader-inline-color] {
  color: var(--darkreader-inline-color) !important;
}
[data-darkreader-inline-fill] {
  fill: var(--darkreader-inline-fill) !important;
}
[data-darkreader-inline-stroke] {
  stroke: var(--darkreader-inline-stroke) !important;
}
[data-darkreader-inline-outline] {
  outline-color: var(--darkreader-inline-outline) !important;
}
[data-darkreader-inline-stopcolor] {
  stop-color: var(--darkreader-inline-stopcolor) !important;
}</style><style class="darkreader darkreader--variables" media="screen">:root {
   --darkreader-neutral-background: #131516;
   --darkreader-neutral-text: #d8d4cf;
   --darkreader-selection-background: #004daa;
   --darkreader-selection-text: #e8e6e3;
}</style><style class="darkreader darkreader--root-vars" media="screen"></style><style class="darkreader darkreader--user-agent" media="screen">html {
    background-color: #181a1b !important;
}
html {
    color-scheme: dark !important;
}
html, body, input, textarea, select, button {
    background-color: #181a1b;
}
html, body, input, textarea, select, button {
    border-color: #736b5e;
    color: #e8e6e3;
}
a {
    color: #3391ff;
}
table {
    border-color: #545b5e;
}
::placeholder {
    color: #b2aba1;
}
input:-webkit-autofill,
textarea:-webkit-autofill,
select:-webkit-autofill {
    background-color: #404400 !important;
    color: #e8e6e3 !important;
}
::-webkit-scrollbar {
    background-color: #202324;
    color: #aba499;
}
::-webkit-scrollbar-thumb {
    background-color: #454a4d;
}
::-webkit-scrollbar-thumb:hover {
    background-color: #575e62;
}
::-webkit-scrollbar-thumb:active {
    background-color: #484e51;
}
::-webkit-scrollbar-corner {
    background-color: #181a1b;
}
* {
    scrollbar-color: #454a4d #202324;
}
::selection {
    background-color: #004daa !important;
    color: #e8e6e3 !important;
}
::-moz-selection {
    background-color: #004daa !important;
    color: #e8e6e3 !important;
}</style>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="last-modified" content="2021-02-04 15:22:41 +0000">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- meta "search-domain" used for google site search function google_search() -->
    <meta name="search-domain" value="http://education.molssi.org/parallel-programming">
    <link rel="stylesheet" type="text/css" href="Parallel%20Programming%20MPI%20Hands-On%20-%20C++_fichiers/bootstrap.css"><style class="darkreader darkreader--sync" media="screen"></style>
    <link rel="stylesheet" type="text/css" href="Parallel%20Programming%20MPI%20Hands-On%20-%20C++_fichiers/bootstrap-theme.css"><style class="darkreader darkreader--sync" media="screen"></style>
    <link rel="stylesheet" type="text/css" href="Parallel%20Programming%20MPI%20Hands-On%20-%20C++_fichiers/lesson.css"><style class="darkreader darkreader--sync" media="screen"></style>
    <link rel="stylesheet" type="text/css" href="Parallel%20Programming%20MPI%20Hands-On%20-%20C++_fichiers/syntax.css"><style class="darkreader darkreader--sync" media="screen"></style>

    



    <!-- Favicons for everyone -->
    <link rel="apple-touch-icon-precomposed" sizes="57x57" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon-precomposed" sizes="60x60" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon-precomposed" sizes="120x120" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon-precomposed" sizes="76x76" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/apple-touch-icon-152x152.png">
    <link rel="icon" type="image/png" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/favicon-196x196.png" sizes="196x196">
    <link rel="icon" type="image/png" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="https://education.molssi.org/parallel-programming/assets/favicons/swc/favicon-128.png" sizes="128x128">
    <meta name="application-name" content="Software Carpentry - Parallel Programming">
    <meta name="msapplication-TileColor" content="#FFFFFF">
    <meta name="msapplication-TileImage" content="../assets/favicons/swc/mstile-144x144.png">
    <meta name="msapplication-square70x70logo" content="../assets/favicons/swc/mstile-70x70.png">
    <meta name="msapplication-square150x150logo" content="../assets/favicons/swc/mstile-150x150.png">
    <meta name="msapplication-wide310x150logo" content="../assets/favicons/swc/mstile-310x150.png">
    <meta name="msapplication-square310x310logo" content="../assets/favicons/swc/mstile-310x310.png">


    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
	<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
	<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->
    <title>Parallel Programming: MPI Hands-On - C++</title>
  <meta name="darkreader" content="9be55190dbf44028a8a1c02497abb0a4"><style class="darkreader darkreader--override" media="screen">.vimvixen-hint {
    background-color: #7b5300 !important;
    border-color: #d8b013 !important;
    color: #f3e8c8 !important;
}
::placeholder {
    opacity: 0.5 !important;
}
#edge-translate-panel-body,
.MuiTypography-body1 {
    color: var(--darkreader-neutral-text) !important;
}
gr-main-header {
    background-color: #0f3a48 !important;
}
.tou-z65h9k,
.tou-mignzq,
.tou-1b6i2ox,
.tou-lnqlqk {
    background-color: var(--darkreader-neutral-background) !important;
}
.tou-75mvi {
    background-color: #032029 !important;
}
.tou-ta9e87,
.tou-1w3fhi0,
.tou-1b8t2us,
.tou-py7lfi,
.tou-1lpmd9d,
.tou-1frrtv8,
.tou-17ezmgn {
    background-color: #0a0a0a !important;
}
.tou-uknfeu {
    background-color: #231603 !important;
}
.tou-6i3zyv {
    background-color: #19576c !important;
}
embed[type="application/pdf"] { filter: invert(100%) contrast(90%); }</style></head>
  <body>

    







    <div class="container">
      






<nav class="navbar navbar-default">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      
      <a href="http://molssi.org/" class="pull-left">
        <img class="navbar-logo" src="Parallel%20Programming%20MPI%20Hands-On%20-%20C++_fichiers/molssi_main_logo.png" alt="The Molecular Sciences Software Institute">
      </a>

      
      <a class="navbar-brand" href="https://education.molssi.org/parallel-programming/index.html">Home</a>

    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

	
        <li><a href="https://education.molssi.org/parallel-programming/CODE_OF_CONDUCT.html">Code of Conduct</a></li>

        
	
        <li><a href="https://education.molssi.org/parallel-programming/setup.html">Setup</a></li>

        
        <li class="dropdown">
          <a href="https://education.molssi.org/parallel-programming/" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Episodes <span class="caret"></span></a>
          <ul class="dropdown-menu">
            
            <li><a href="https://education.molssi.org/parallel-programming/01-introduction/index.html">Introduction</a></li>
            
            <li><a href="https://education.molssi.org/parallel-programming/02-distributed-intro/index.html">Introduction to Distributed-Memory Parallelization</a></li>
            
            <li><a href="https://education.molssi.org/parallel-programming/03-distributed-examples-mpi4py/index.html">MPI Hands-On - mpi4py</a></li>
            
            <li><a href="https://education.molssi.org/parallel-programming/04-distributed-examples/index.html">MPI Hands-On - C++</a></li>
            
            <li><a href="https://education.molssi.org/parallel-programming/05-shared-intro/index.html">Introduction to Shared-Memory Parallelization</a></li>
            
            <li><a href="https://education.molssi.org/parallel-programming/06-shared-examples/index.html">OpenMP Hands-On</a></li>
            
	    <li role="separator" class="divider"></li>
            <li><a href="https://education.molssi.org/parallel-programming/aio.html">All in one page (Beta)</a></li>
          </ul>
        </li>
	

	
	
        <li class="dropdown">
          <a href="https://education.molssi.org/parallel-programming/" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Extras <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="https://education.molssi.org/parallel-programming/reference.html">Reference</a></li>
            
            <li><a href="https://education.molssi.org/parallel-programming/about/index.html">About</a></li>
            
            <li><a href="https://education.molssi.org/parallel-programming/discuss/index.html">Discussion</a></li>
            
            <li><a href="https://education.molssi.org/parallel-programming/figures/index.html">Figures</a></li>
            
            <li><a href="https://education.molssi.org/parallel-programming/guide/index.html">Instructor Notes</a></li>
            
          </ul>
        </li>
	

	
        <li><a href="https://education.molssi.org/parallel-programming/LICENSE.html">License</a></li>
	
	<li><a href="https://github.com/MolSSI-Education/parallel-programming/edit/gh-pages/_episodes/04-distributed-examples.md">Improve this page <span class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a></li>
	
      </ul>
      <form class="navbar-form navbar-right" role="search" id="search" onsubmit="google_search(); return false;">
        <div class="form-group">
          <input type="text" id="google-search" placeholder="Search..." aria-label="Google site search">
        </div>
      </form>
    </div>
  </div>
</nav>

















<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="https://education.molssi.org/parallel-programming/03-distributed-examples-mpi4py/index.html"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
    <h3 class="maintitle"><a href="https://education.molssi.org/parallel-programming/">Parallel Programming</a></h3>
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="https://education.molssi.org/parallel-programming/05-shared-intro/index.html"><span class="glyphicon glyphicon-menu-right" aria-hidden="true"></span><span class="sr-only">next episode</span></a>
      
    </h3>
  </div>
</div>

<article>
<div class="row">
  <div class="col-md-1">
  </div>
  <div class="col-md-10">
    <h1 class="maintitle">MPI Hands-On - C++</h1>
  </div>
  <div class="col-md-1">
  </div>
</div>


<blockquote class="objectives">
  <h2>Overview</h2>

  <div class="row">
    <div class="col-md-3">
      <strong>Teaching:</strong> 0 min
      <br>
      <strong>Exercises:</strong> 90 min
    </div>
    <div class="col-md-9">
      <strong>Questions</strong>
      <ul>
	
	<li><p>How can I use MPI to parallelize a compiled code?</p>
</li>
	
      </ul>
    </div>
  </div>

  <div class="row">
    <div class="col-md-3">
    </div>
    <div class="col-md-9">
      <strong>Objectives</strong>
      <ul>
	
	<li><p>Compile and run C++ codes that are parallelized using MPI.</p>
</li>
	
	<li><p>Use proper MPI error handling.</p>
</li>
	
	<li><p>Learn how to use non-blocking communication methods.</p>
</li>
	
	<li><p>Use a debugger with an parallelized code.</p>
</li>
	
      </ul>
    </div>
  </div>

</blockquote>

<h2 id="1-example-1">1. Example 1</h2>

<h3 id="writing-hello-world">Writing Hello World</h3>

<p>We’ll start with the first example in <a href="https://github.com/MolSSI-Education/parallel-programming/tree/gh-pages/examples/mpi/hello">mpi/hello</a>, which is a simple Hello World code:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;iostream&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Hello World!"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Acquire a copy of the example files for this lesson, and then compile and run the example code:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone git@github.com:MolSSI-Education/parallel-programming.git
<span class="nv">$ </span><span class="nb">cd </span>parallel-programming/examples/mpi/hello
<span class="nv">$ </span><span class="nb">mkdir </span>build
<span class="nv">$ </span><span class="nb">cd </span>build
<span class="nv">$ </span>cmake <span class="nt">-DCMAKE_C_COMPILER</span><span class="o">=</span>mpicc <span class="nt">-DCMAKE_CXX_COMPILER</span><span class="o">=</span>mpicxx <span class="nt">-DCMAKE_Fortran_COMPILER</span><span class="o">=</span>mpifort ..
<span class="nv">$ </span>make
<span class="nv">$ </span>./hello
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hello World!
</code></pre></div></div>

<h3 id="getting-started-with-mpi">Getting Started with MPI</h3>

<p>Let’s try running this code on multiple processes.
This is done using the <code class="language-plaintext highlighter-rouge">mpiexec</code> command.
Many environments also provide an <code class="language-plaintext highlighter-rouge">mpirun</code> command, which usually - but not always - works the same way.
Whenever possible, you should use <code class="language-plaintext highlighter-rouge">mpiexec</code> and not <code class="language-plaintext highlighter-rouge">mpirun</code>, in order to guarantee more consistent results.</p>

<blockquote class="callout">
  <h2 id="mpi---mpiexec-vs-mpirun">MPI - <code class="language-plaintext highlighter-rouge">mpiexec</code> vs <code class="language-plaintext highlighter-rouge">mpirun</code></h2>
  <p>MPI stands for <strong>‘message passing interface’</strong> and is a message passing standard which is designed to work on a variety of parallel computing architectures. The <a href="https://www.mpi-forum.org/docs/drafts/mpi-2018-draft-report.pdf">MPI standard</a>
 defines how syntax and semantics of a library of routines. There are a 
number of implementations of this standard including OpenMPI, MPICH, and
 MS MPI.</p>

  <p>The primary difference between <code class="language-plaintext highlighter-rouge">mpiexec</code> and <code class="language-plaintext highlighter-rouge">mpirun</code> is that <code class="language-plaintext highlighter-rouge">mpiexec</code> is defined as part of the MPI standard, while <code class="language-plaintext highlighter-rouge">mpirun</code> is not.  Different implementations of MPI (i.e. OpenMPI, MPICH, MS MPI, etc.) are not guaranteed to implement <code class="language-plaintext highlighter-rouge">mpirun</code>, or might implement different options for <code class="language-plaintext highlighter-rouge">mpirun</code>.  Technically, the MPI standard doesn’t actually require that MPI implementations implement <code class="language-plaintext highlighter-rouge">mpiexec</code> either, but the standard does at least describe guidelines for how <code class="language-plaintext highlighter-rouge">mpiexec</code> should work.  Because of this, <code class="language-plaintext highlighter-rouge">mpiexec</code> is generally the preferred command.</p>

</blockquote>

<p>The general format for lanching a code on multiple processes is:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mpiexec <span class="nt">-n</span> &lt;number_of_processes&gt; &lt;command_to_launch_code&gt;
</code></pre></div></div>

<p>For example, to launch <code class="language-plaintext highlighter-rouge">hello</code> on 4 processes, do:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./hello
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hello World!
Hello World!
Hello World!
Hello World!
</code></pre></div></div>

<p>When you execute the above command, <code class="language-plaintext highlighter-rouge">mpiexec</code> launches 4 different instances of <code class="language-plaintext highlighter-rouge">./hello</code> simultaneously, which each print “Hello World!”.</p>

<p>Typically, as long as you have at least 4 processors on the machine 
you are running on, each process will be launched on a different 
processor; however, certain environment variables and optional arguments
 to <code class="language-plaintext highlighter-rouge">mpiexec</code> can change this behavior.
Each process runs the code in <code class="language-plaintext highlighter-rouge">hello</code> independently of the others.</p>

<p>It might not be obvious yet, but the processes <code class="language-plaintext highlighter-rouge">mpiexec</code> launches aren’t completely unaware of one another.
The <code class="language-plaintext highlighter-rouge">mpiexec</code> 
adds each of the processes to an MPI communicator, which enables each of
 the processes to send and receive information to one another via MPI.
The MPI communicator that spans all of the processes launched by <code class="language-plaintext highlighter-rouge">mpiexec</code> is called <code class="language-plaintext highlighter-rouge">MPI_COMM_WORLD</code>.</p>

<p>We can use the MPI library to get some information about the <code class="language-plaintext highlighter-rouge">MPI_COMM_WORLD</code> communicator and the processes within it.
Edit <code class="language-plaintext highlighter-rouge">hello.cpp</code> so that it reads as follows:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;iostream&gt;
#include &lt;mpi.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Initialize MPI</span>
  <span class="c1">// This must always be called before any other MPI functions</span>
  <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

  <span class="c1">// Get the number of processes in MPI_COMM_WORLD</span>
  <span class="kt">int</span> <span class="n">world_size</span><span class="p">;</span>
  <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">world_size</span><span class="p">);</span>

  <span class="c1">// Get the rank of this process in MPI_COMM_WORLD</span>
  <span class="kt">int</span> <span class="n">my_rank</span><span class="p">;</span>
  <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">my_rank</span><span class="p">);</span>

  <span class="c1">// Print out information about MPI_COMM_WORLD</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"World Size: "</span> <span class="o">&lt;&lt;</span> <span class="n">world_size</span> <span class="o">&lt;&lt;</span> <span class="s">"   Rank: "</span> <span class="o">&lt;&lt;</span> <span class="n">my_rank</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

  <span class="c1">// Finalize MPI</span>
  <span class="c1">// This must always be called after all other MPI functions</span>
  <span class="n">MPI_Finalize</span><span class="p">();</span>

  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Recompile the code:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
</code></pre></div></div>

<p>In the above code we first include the MPI library header, <code class="language-plaintext highlighter-rouge">mpi.h</code>.
Then, we call <code class="language-plaintext highlighter-rouge">MPI_Init()</code>.
This function <strong>must</strong> be called before any other MPI functions, and is typically one of the first lines of an MPI-parallelized code.
Then, we call <code class="language-plaintext highlighter-rouge">MPI_Comm_size()</code> to get the number of processes in <code class="language-plaintext highlighter-rouge">MPI_COMM_WORLD</code>, which corresponds to the number of processes launched whenever <code class="language-plaintext highlighter-rouge">mpiexec</code> is executed at the command line.
Each of these processes is assigned a uniqe rank, which is an integer that ranges from <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">world_size - 1</code>.
The rank of a process allows it to be identified whenever processes 
communicate with one another.
For example, in some cases we might want rank 2 to send some information
 to rank 4, or we might want rank 0 to receive information from all of 
the other processes.
Calling <code class="language-plaintext highlighter-rouge">MPI_Comm_rank()</code> returns the rank of the process calling it within <code class="language-plaintext highlighter-rouge">MPI_COMM_WORLD</code>.</p>

<p>Go ahead and run the code now:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./hello
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>World Size: 4   Rank: 1
World Size: 4   Rank: 0
World Size: 4   Rank: 2
World Size: 4   Rank: 3
</code></pre></div></div>

<p>As you can see, the <code class="language-plaintext highlighter-rouge">MPI_Comm_size()</code> function outputs 4, which is the total number of ranks we told <code class="language-plaintext highlighter-rouge">mpiexec</code> to run with (through the <code class="language-plaintext highlighter-rouge">-n</code> argument).
Each of the processes is assigned a rank in the range of 0 to 3.</p>

<p>As you can see, the ranks don’t necessarily print out their messages in order; whichever rank completes the <code class="language-plaintext highlighter-rouge">cout</code> first will print out its message first.
If you run the code again, the ranks are likely to print thier message in a different order:</p>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>World Size: 4   Rank: 2
World Size: 4   Rank: 0
World Size: 4   Rank: 3
World Size: 4   Rank: 1
</code></pre></div></div>

<p>You can also try rerunning with a different value for the <code class="language-plaintext highlighter-rouge">-n</code> <code class="language-plaintext highlighter-rouge">mpiexec</code> argument.
For example:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mpiexec <span class="nt">-n</span> 2 ./hello
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>World Size: 2   Rank: 0
World Size: 2   Rank: 1
</code></pre></div></div>

<h3 id="error-handling-with-mpi">Error Handling with MPI</h3>

<p>If an error forces an MPI program to exit, it should <strong>never</strong> just call <code class="language-plaintext highlighter-rouge">return</code> or <code class="language-plaintext highlighter-rouge">exit</code>.
This is because calling <code class="language-plaintext highlighter-rouge">return</code> or <code class="language-plaintext highlighter-rouge">exit</code>
 might terminate one of the MPI processes, but leave others running (but
 not doing anything productive) indefintely.
If you’re not careful, you could waste massive amounts of computational 
resources running a failed calculation your thought had terminated.
Instead, MPI-parallelized codes should call <code class="language-plaintext highlighter-rouge">MPI_Abort()</code> when something goes wrong, as this function will ensure all MPI processes terminate.
The <code class="language-plaintext highlighter-rouge">MPI_Abort</code> 
function takes two arguments: the first is the communicator 
corresponding to the set of MPI processes to terminate (this should 
generally be <code class="language-plaintext highlighter-rouge">MPI_COMM_WORLD</code>), while the second is an error code that will be returned to the environment.</p>

<p>It is also useful to keep in mind that most MPI functions have a 
return value that indicates whether the function completed succesfully.
If this value is equal to <code class="language-plaintext highlighter-rouge">MPI_SUCCESS</code>, the function was executed successfully; otherwise, the function call failed.
By default, MPI functions automatically abort if they encounter an error, so you’ll only ever get a return value of <code class="language-plaintext highlighter-rouge">MPI_SUCCESS</code>.
If you want to handle MPI errors yourself, you can call <code class="language-plaintext highlighter-rouge">MPI_Errhandler_set(MPI_COMM_WORLD, MPI_ERRORS_RETURN)</code>; if you do this, you must check the return value of every MPI function and call <code class="language-plaintext highlighter-rouge">MPI_Abort</code> if it is not equal to <code class="language-plaintext highlighter-rouge">MPI_SUCCESS</code>.
For example, when initializing MPI, you might do the following:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="p">(</span><span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="o">&amp;</span><span class="n">argv</span><span class="p">)</span> <span class="o">!=</span> <span class="n">MPI_SUCCESS</span><span class="p">)</span> <span class="n">MPI_Abort</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</code></pre></div></div>

<h2 id="example-2">Example 2</h2>

<h3 id="basic-infrastructure">Basic Infrastructure</h3>

<p>We will now do some work with the the example in <a href="https://github.com/MolSSI-Education/parallel-programming/tree/gh-pages/examples/mpi/average">examples/mpi/average</a>, which does some simple math.
Run the code now.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd </span>parallel-programming/examples/mpi/average
<span class="nv">$ </span><span class="nb">mkdir </span>build
<span class="nv">$ </span><span class="nb">cd </span>build
<span class="nv">$ </span>cmake <span class="nt">-DCMAKE_C_COMPILER</span><span class="o">=</span>mpicc <span class="nt">-DCMAKE_CXX_COMPILER</span><span class="o">=</span>mpicxx <span class="nt">-DCMAKE_Fortran_COMPILER</span><span class="o">=</span>mpifort ..
<span class="nv">$ </span>make
<span class="nv">$ </span>./average
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average: 100000001.5
</code></pre></div></div>

<p>Let’s learn something about which parts of this code account for most of the run time.
MPI provides a timer, <code class="language-plaintext highlighter-rouge">MPI_Wtime()</code>, which returns the current walltime.
We can use this function to determine how long each section of the code takes to run.</p>

<p>For example, to determine how much time is spent initializing array <code class="language-plaintext highlighter-rouge">a</code>, do the following:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Initialize a</span>
  <span class="kt">double</span> <span class="n">start_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="kt">double</span> <span class="o">*</span><span class="n">a</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="kt">double</span> <span class="n">end_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Initialize a time: "</span> <span class="o">&lt;&lt;</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="p">}</span>
</code></pre></div></div>

<p>As the above code indicates, we don’t really want every rank to print the timings, since that could look messy in the output.
Instead, we have only rank 0 print this information.
Of course, this requires that we add a few lines near the top of the code to initialize MPI and query the rank of each process:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Initialize MPI</span>
  <span class="kt">int</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">my_rank</span><span class="p">;</span>
  <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
  <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">world_size</span><span class="p">);</span>
  <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">my_rank</span><span class="p">);</span>
</code></pre></div></div>

<p>Also determine and print the timings of each of the other sections of the code: the intialization of array <code class="language-plaintext highlighter-rouge">b</code>, the addition of the two arrays, and the final averaging of the result.
Your code should look something like this:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include &lt;iostream&gt;
#include &lt;mpi.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Initialize MPI</span>
  <span class="kt">int</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">my_rank</span><span class="p">;</span>
  <span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
  <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">world_size</span><span class="p">);</span>
  <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">my_rank</span><span class="p">);</span>

  <span class="kt">int</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">200000000</span><span class="p">;</span>

  <span class="c1">// Initialize a</span>
  <span class="kt">double</span> <span class="n">start_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="kt">double</span> <span class="o">*</span><span class="n">a</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="kt">double</span> <span class="n">end_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Initialize a time: "</span> <span class="o">&lt;&lt;</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// Initialize b</span>
  <span class="n">start_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="kt">double</span> <span class="o">*</span><span class="n">b</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="kt">double</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="n">end_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Initialize b time: "</span> <span class="o">&lt;&lt;</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="p">}</span>
  
  <span class="c1">// Add the two arrays</span>
  <span class="n">start_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
  <span class="p">}</span>
  <span class="n">end_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Add arrays time: "</span> <span class="o">&lt;&lt;</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// Average the result</span>
  <span class="n">start_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="kt">double</span> <span class="n">average</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">average</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="kt">double</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="n">end_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Average result time: "</span> <span class="o">&lt;&lt;</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="p">.</span><span class="n">precision</span><span class="p">(</span><span class="mi">12</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Average: "</span> <span class="o">&lt;&lt;</span> <span class="n">average</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="k">delete</span> <span class="p">[]</span> <span class="n">a</span><span class="p">;</span>
  <span class="k">delete</span> <span class="p">[]</span> <span class="n">b</span><span class="p">;</span>
  <span class="n">MPI_Finalize</span><span class="p">();</span>
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Now compile and run the code again:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>./average
</code></pre></div></div>

<pre><code class="language-output">Initialize a time: 0.544075
Initialize b time: 0.624939
Add arrays time: 0.258915
Average result time: 0.266418
Average: 100000001.5
</code></pre>

<h3 id="point-to-point-communication">Point-to-Point Communication</h3>

<p>You can try running this on multiple ranks now:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./average
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Initialize a time: 0.640894
Initialize b time: 0.893775
Add arrays time: 1.38309
Average result time: 0.330192
Average: 100000001.5
</code></pre></div></div>

<p>Running on multiple ranks doesn’t help with the timings, because each
 rank is duplicating all of the same work.
In some ways, running on multiple ranks makes the timings worse, because
 all of the processes are forced to compete for the same computational 
resources.
Memory bandwidth in particular is likely a serious problem due to the 
extremely large arrays that must be accessed and manipulated by each 
process.
We want the ranks to cooperate on the problem, with each rank working on
 a different part of the calculation.
In this example, that means that different ranks will work on different 
parts of the arrays <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>, and then the results on each rank will be summed across all the ranks.</p>

<p>In this section, we will handle the details of the communication between processes using <em>point-to-point</em>
 communication.
Point-to-point communication involves cases in which a code explicitly 
instructs one specific process to send/recieve information to/from 
another specific process.
The primary functions associated with this approach are <code class="language-plaintext highlighter-rouge">MPI_Send()</code> and <code class="language-plaintext highlighter-rouge">MPI_Recv()</code>, which are involve the following arguments:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Send</span><span class="p">(</span><span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">buf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">datatype</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dest</span><span class="p">,</span> <span class="kt">int</span> <span class="n">tag</span><span class="p">,</span>  <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">);</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">buf</code> — pointer to the start of the buffer being sent</li>
  <li><code class="language-plaintext highlighter-rouge">count</code> — number of elements to send</li>
  <li><code class="language-plaintext highlighter-rouge">datatype</code> — MPI data type of each element</li>
  <li><code class="language-plaintext highlighter-rouge">dest</code> — rank of destination process</li>
  <li><code class="language-plaintext highlighter-rouge">tag</code>  — message tag</li>
  <li><code class="language-plaintext highlighter-rouge">comm</code> — the communicator to use</li>
</ul>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">MPI_Recv</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">buf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">datatype</span><span class="p">,</span> <span class="kt">int</span> <span class="n">source</span><span class="p">,</span> <span class="kt">int</span> <span class="n">tag</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">,</span> <span class="n">MPI_Status</span> <span class="o">*</span><span class="n">status</span><span class="p">);</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">buf</code> — pointer to the start of the buffer to receive the message</li>
  <li><code class="language-plaintext highlighter-rouge">count</code> — maximum number of elements the buffer can hold</li>
  <li><code class="language-plaintext highlighter-rouge">datatype</code> — MPI data type of each element</li>
  <li><code class="language-plaintext highlighter-rouge">source</code> — rank of source process —  <code class="language-plaintext highlighter-rouge">MPI_ANY_SOURCE</code> matches any process</li>
  <li><code class="language-plaintext highlighter-rouge">tag</code>  — message tag (integer <code class="language-plaintext highlighter-rouge">&gt;= 0</code>) — <code class="language-plaintext highlighter-rouge">MPI_ANY_TAG</code> matches any tag</li>
  <li><code class="language-plaintext highlighter-rouge">comm</code> — the communicator to use</li>
  <li><code class="language-plaintext highlighter-rouge">status</code> — pointer to the structure in which to store status</li>
</ul>

<p>We need to decide what parts of the arrays each of the ranks will work on; this is more generally known as a rank’s workload.
Add the following code just before the initialization of array <code class="language-plaintext highlighter-rouge">a</code>:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Determine the workload of each ran</span>
  <span class="kt">int</span> <span class="n">workloads</span><span class="p">[</span><span class="n">world_size</span><span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">world_size</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">workloads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">N</span> <span class="o">/</span> <span class="n">world_size</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span> <span class="o">%</span> <span class="n">world_size</span> <span class="p">)</span> <span class="n">workloads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">++</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="kt">int</span> <span class="n">my_start</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">my_rank</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">my_start</span> <span class="o">+=</span>	<span class="n">workloads</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
  <span class="p">}</span>
  <span class="kt">int</span> <span class="n">my_end</span> <span class="o">=</span> <span class="n">my_start</span>	<span class="o">+</span> <span class="n">workloads</span><span class="p">[</span><span class="n">my_rank</span><span class="p">];</span>
</code></pre></div></div>

<p>In the above code, <code class="language-plaintext highlighter-rouge">my_start</code> and <code class="language-plaintext highlighter-rouge">my_end</code> represent the range over which each rank will perform mathematical operations on the arrays.</p>

<p>We’ll start by parallelizing the code that averages the result.
Update the range of the <code class="language-plaintext highlighter-rouge">for</code> loop in this part of the code to the following:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="n">my_start</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">my_end</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</code></pre></div></div>

<p>This will ensure that each rank is only calculating elements <code class="language-plaintext highlighter-rouge">my_start</code> through <code class="language-plaintext highlighter-rouge">my_end</code> of the sum.
We then need the ranks to communicate their individually calculated sums so that we can calculate the global sum.
To do this, add the following immediately after the end of the <code class="language-plaintext highlighter-rouge">for</code> loop:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">if</span> <span class="p">(</span> <span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">world_size</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">double</span> <span class="n">partial_average</span><span class="p">;</span>
      <span class="n">MPI_Status</span> <span class="n">status</span><span class="p">;</span>
      <span class="n">MPI_Recv</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">partial_average</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span> <span class="p">);</span>
      <span class="n">average</span> <span class="o">+=</span> <span class="n">partial_average</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">else</span> <span class="p">{</span>
    <span class="n">MPI_Send</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">average</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span> <span class="p">);</span>
  <span class="p">}</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">MPI_DOUBLE</code> parameter tells MPI what type of information is being communicated by the <code class="language-plaintext highlighter-rouge">Send</code> and <code class="language-plaintext highlighter-rouge">Recv</code> calls.
In this case, we are sending a array of double precision numbers.
If you are communicating information of a different datatype, consult the following:</p>

<table class="table table-striped">
  <thead>
    <tr>
      <th style="text-align: left"><strong>MPI data type</strong></th>
      <th style="text-align: left"><strong>C data type</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_BYTE</code></td>
      <td style="text-align: left">8 binary digits</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_CHAR</code></td>
      <td style="text-align: left">char</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_UNSIGNED_CHAR</code></td>
      <td style="text-align: left">unsigned char</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_SHORT</code></td>
      <td style="text-align: left">signed short int</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_UNSIGNED_SHORT</code></td>
      <td style="text-align: left">unsigned short int</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_INT</code></td>
      <td style="text-align: left">signed int</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_UNSIGNED</code></td>
      <td style="text-align: left">unsigned int</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_LONG</code></td>
      <td style="text-align: left">signed long int</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_UNSIGNED_LONG</code></td>
      <td style="text-align: left">unsigned long int</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_FLOAT</code></td>
      <td style="text-align: left">float</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_DOUBLE</code></td>
      <td style="text-align: left">double</td>
    </tr>
    <tr>
      <td style="text-align: left">etc.</td>
      <td style="text-align: left">&nbsp;</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_PACKED</code></td>
      <td style="text-align: left">define your own with</td>
    </tr>
    <tr>
      <td style="text-align: left">&nbsp;</td>
      <td style="text-align: left"><a href="https://www.mpich.org/static/docs/v3.2/www3/MPI_Pack.html"><code class="language-plaintext highlighter-rouge">MPI_Pack</code></a>/<a href="https://www.mpich.org/static/docs/v3.2/www3/MPI_Pack.html"><code class="language-plaintext highlighter-rouge">MPI_Unpack</code></a></td>
    </tr>
  </tbody>
</table>

<p>Now compile and run the code again:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./average
</code></pre></div></div>

<pre><code class="language-output">Initialize a time: 0.63251
Initialize b time: 1.31379
Add arrays time: 1.89099
Average result time: 0.100575
Average: 100000001.5
</code></pre>

<p>You can see that the amount of time spent calculating the average has indeed gone down.</p>

<p>Parallelizing the part of the code that adds the two arrays is much easier.
All you need to do is update the range over which the <code class="language-plaintext highlighter-rouge">for</code> loop iterates:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="n">my_start</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">my_end</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</code></pre></div></div>

<p>Now compile and run the code again:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./average
</code></pre></div></div>

<pre><code class="language-output">Initialize a time: 0.636685
Initialize b time: 1.66542
Add arrays time: 0.466888
Average result time: 0.0871116
Average: 100000001.5
</code></pre>

<p>The array addition time has gone down nicely.
Surprisingly enough, the most expensive part of the calculation is now the initialization of the arrays <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>.
Updating the range over which those loops iterate speeds up those parts of the calation:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Initialze a</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="n">my_start</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">my_end</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
<span class="p">...</span>
  <span class="c1">// Initialize b</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="n">my_start</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">my_end</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>./average
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Initialize a time: 0.159471
Initialize b time: 0.183946
Add arrays time: 0.193497
Average result time: 0.0847806
Average: 100000001.5
</code></pre></div></div>

<h3 id="reducing-the-memory-footprint">Reducing the Memory Footprint</h3>

<p>The simulation is running much faster now thanks to the parallelization we have added.
If that’s all we care about, we could stop working on the code now.
In reality, though, <strong>time</strong> is only one resource we should be concerned about.
Another resource that is often even more important is <strong>memory</strong>.
The changes we have made to the code make it run faster, but don’t 
decrease its memory footprint in any way: each rank allocates arrays <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code> with <code class="language-plaintext highlighter-rouge">N</code> double precision values.
That means that each rank allocates <code class="language-plaintext highlighter-rouge">2*N</code> double precision values; across all of our ranks, that corresponds to a total of <code class="language-plaintext highlighter-rouge">2*nproc*world_size</code> double precision values.
Running on more processors might decrease our run time, but it increases our memory footprint!</p>

<p>Of course, there isn’t really a good reason for each rank to allocate the entire arrays of size <code class="language-plaintext highlighter-rouge">N</code>, because each rank will only ever use values within the range of <code class="language-plaintext highlighter-rouge">my_start</code> to <code class="language-plaintext highlighter-rouge">my_end</code>.
Let’s modify the code so that each rank allocates <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code> to a size of <code class="language-plaintext highlighter-rouge">workloads[my_rank]</code>.</p>

<p>Replace the initialization of <code class="language-plaintext highlighter-rouge">a</code> with:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kt">double</span> <span class="o">*</span><span class="n">a</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="p">[</span> <span class="n">workloads</span><span class="p">[</span><span class="n">my_rank</span><span class="p">]</span> <span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">workloads</span><span class="p">[</span><span class="n">my_rank</span><span class="p">];</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span>
  <span class="p">}</span>
</code></pre></div></div>

<p>Replace the initialization of <code class="language-plaintext highlighter-rouge">b</code> with:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kt">double</span> <span class="o">*</span><span class="n">b</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="p">[</span> <span class="n">workloads</span><span class="p">[</span><span class="n">my_rank</span><span class="p">]</span> <span class="p">];</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">workloads</span><span class="p">[</span><span class="n">my_rank</span><span class="p">];</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="kt">double</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">my_start</span><span class="p">);</span>
  <span class="p">}</span>
</code></pre></div></div>

<p>Replace the range of the loops that add and average the arrays to <code class="language-plaintext highlighter-rouge">for (int i=0; i&lt;workloads[my_rank]; i++)</code>.</p>

<p>Now compile and run the code again:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>./average
</code></pre></div></div>

<pre><code class="language-output">Initialize a time: 0.16013
Initialize b time: 0.176896
Add arrays time: 0.190774
Average result time: 0.0871552
Average: 100000001.5
</code></pre>

<h3 id="collective-communication">Collective Communication</h3>

<p>Previously, we used <strong>point-to-point communication</strong> (i.e. <code class="language-plaintext highlighter-rouge">MPI_Send</code> and <code class="language-plaintext highlighter-rouge">MPI_Recv</code>) to sum the results across all ranks:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">if</span> <span class="p">(</span> <span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">world_size</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">double</span> <span class="n">partial_average</span><span class="p">;</span>
      <span class="n">MPI_Status</span> <span class="n">status</span><span class="p">;</span>
      <span class="n">MPI_Recv</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">partial_average</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span> <span class="p">);</span>
      <span class="n">average</span> <span class="o">+=</span> <span class="n">partial_average</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">else</span> <span class="p">{</span>
    <span class="n">MPI_Send</span><span class="p">(</span> <span class="o">&amp;</span><span class="n">average</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span> <span class="p">);</span>
  <span class="p">}</span>
</code></pre></div></div>

<p>MPI provides many <strong>collective communication</strong> functions, which automate many processes that can be complicated to write out using only point-to-point communication.
One particularly useful collective communication function is <code class="language-plaintext highlighter-rouge">MPI_Reduce()</code>:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kt">int</span> <span class="n">MPI_Reduce</span><span class="p">(</span><span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">sendbuf</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">recvbuf</span><span class="p">,</span> <span class="kt">int</span> <span class="n">count</span><span class="p">,</span> <span class="n">MPI_Datatype</span> <span class="n">datatype</span><span class="p">,</span>
                 <span class="n">MPI_Op</span> <span class="n">op</span><span class="p">,</span> <span class="kt">int</span> <span class="n">root</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sendbuf</code> — address of send buffer</li>
  <li><code class="language-plaintext highlighter-rouge">recvbuf</code> — address of receive buffer</li>
  <li><code class="language-plaintext highlighter-rouge">count</code> — number of elements in send buffer</li>
  <li><code class="language-plaintext highlighter-rouge">datatype</code> — MPI data type of each element</li>
  <li><code class="language-plaintext highlighter-rouge">op</code> — reduce operation</li>
  <li><code class="language-plaintext highlighter-rouge">root</code> — rank of root process</li>
  <li><code class="language-plaintext highlighter-rouge">comm</code> — the communicator to use</li>
</ul>

<p>Possible values for <code class="language-plaintext highlighter-rouge">op</code> are:</p>

<table class="table table-striped">
  <thead>
    <tr>
      <th style="text-align: left"><strong>Operation</strong></th>
      <th style="text-align: left">Description</th>
      <th style="text-align: left">Datatype</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_MAX</code></td>
      <td style="text-align: left">maximum</td>
      <td style="text-align: left">integer,float</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_MIN</code></td>
      <td style="text-align: left">minimum</td>
      <td style="text-align: left">integer,float</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_SUM</code></td>
      <td style="text-align: left">sum</td>
      <td style="text-align: left">integer,float</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_PROD</code></td>
      <td style="text-align: left">product</td>
      <td style="text-align: left">integer,float</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_LAND</code></td>
      <td style="text-align: left">logical AND</td>
      <td style="text-align: left">integer</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_BAND</code></td>
      <td style="text-align: left">bit-wise AND</td>
      <td style="text-align: left">integer,MPI_BYTE</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_LOR</code></td>
      <td style="text-align: left">logical OR</td>
      <td style="text-align: left">integer</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_BOR</code></td>
      <td style="text-align: left">bit-wise OR</td>
      <td style="text-align: left">integer,MPI_BYTE</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_LXOR</code></td>
      <td style="text-align: left">logical XOR</td>
      <td style="text-align: left">integer</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_BXOR</code></td>
      <td style="text-align: left">bit-wise XOR</td>
      <td style="text-align: left">integer,MPI_BYTE</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_MAXLOC</code></td>
      <td style="text-align: left">max value and location</td>
      <td style="text-align: left">float</td>
    </tr>
    <tr>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">MPI_MINLOC</code></td>
      <td style="text-align: left">min value and location</td>
      <td style="text-align: left">float</td>
    </tr>
  </tbody>
</table>

<p>We will use the <code class="language-plaintext highlighter-rouge">MPI_Reduce()</code> function to sum a value across all ranks, without all of the point-to-point communication code we needed earlier.
Replace all of your point-to-point communication code above with:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kt">double</span> <span class="n">partial_average</span> <span class="o">=</span> <span class="n">average</span><span class="p">;</span>
  <span class="n">MPI_Reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="n">partial_average</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">average</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="n">MPI_SUM</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
</code></pre></div></div>

<p>Compiling and running with this change should produce the same results as before.</p>

<p>Note that in addition to enabling us to write simpler-looking code, 
collective communication operations tend to be faster than what we can 
achieve by trying to write our own communication operations using 
point-to-point calls.</p>

<h2 id="example-3">Example 3</h2>

<p>Next, view <a href="https://github.com/MolSSI-Education/parallel-programming/tree/gh-pages/examples/mpi/mc">examples/mc</a> which is a simple Monte-Carlo simulation.
Compile and run the code now.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd </span>parallel-programming/examples/mpi/mc
<span class="nv">$ </span><span class="nb">mkdir </span>build
<span class="nv">$ </span><span class="nb">cd </span>build
<span class="nv">$ </span>cmake <span class="nt">-DCMAKE_C_COMPILER</span><span class="o">=</span>mpicc <span class="nt">-DCMAKE_CXX_COMPILER</span><span class="o">=</span>mpicxx <span class="nt">-DCMAKE_Fortran_COMPILER</span><span class="o">=</span>mpifort ..
<span class="nv">$ </span>make
<span class="nv">$ </span>./mc
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
497000   -6.28643
498000   -6.28989
499000   -5.96743
500000   -6.06861
Total simulation time: 2.59121
    Energy time:       2.47059
    Decision time:     0.0425119
</code></pre></div></div>

<p>As you can see, the code already has some timings, and the vast 
majority of time is spent in the calls to ‘get_particle_energy()’.
That is where we will focus our parallelization efforts.</p>

<p>The function in question is:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">double</span> <span class="nf">get_particle_energy</span><span class="p">(</span><span class="kt">double</span> <span class="o">*</span><span class="n">coordinates</span><span class="p">,</span> <span class="kt">int</span> <span class="n">particle_count</span><span class="p">,</span> <span class="kt">double</span> <span class="n">box_length</span><span class="p">,</span> <span class="kt">int</span> <span class="n">i_particle</span><span class="p">,</span> <span class="kt">double</span> <span class="n">cutoff2</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">double</span> <span class="n">e_total</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span>
  <span class="kt">double</span> <span class="o">*</span><span class="n">i_position</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">coordinates</span><span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="n">i_particle</span><span class="p">];</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j_particle</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j_particle</span> <span class="o">&lt;</span> <span class="n">particle_count</span><span class="p">;</span> <span class="n">j_particle</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span> <span class="n">i_particle</span> <span class="o">!=</span> <span class="n">j_particle</span> <span class="p">)</span> <span class="p">{</span>
      <span class="kt">double</span> <span class="o">*</span><span class="n">j_position</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">coordinates</span><span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="n">j_particle</span><span class="p">];</span>
      <span class="kt">double</span> <span class="n">rij2</span> <span class="o">=</span> <span class="n">minimum_image_distance</span><span class="p">(</span> <span class="n">i_position</span><span class="p">,</span> <span class="n">j_position</span><span class="p">,</span> <span class="n">box_length</span> <span class="p">);</span>
      <span class="k">if</span> <span class="p">(</span> <span class="n">rij2</span> <span class="o">&lt;</span> <span class="n">cutoff2</span> <span class="p">)</span> <span class="p">{</span>
        <span class="n">e_total</span> <span class="o">+=</span> <span class="n">lennard_jones_potential</span><span class="p">(</span><span class="n">rij2</span><span class="p">);</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">return</span> <span class="n">e_total</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This looks like it should be fairly straightforward to parallelize: it consists of a single <code class="language-plaintext highlighter-rouge">for</code>
 loop which just sums the interaction energies of particle pairs.
To parallelize this loop, we need each rank to compute the interaction 
energies of a subset of these pairs, and then sum the energy across all 
ranks.</p>

<p>The <code class="language-plaintext highlighter-rouge">get_particle_energy()</code>
 function is going to need to know some basic information about the MPI 
communicator, so add the MPI communicator to its parameters:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">double</span> <span class="nf">get_particle_energy</span><span class="p">(</span><span class="kt">double</span> <span class="o">*</span><span class="n">coordinates</span><span class="p">,</span> <span class="kt">int</span> <span class="n">particle_count</span><span class="p">,</span> <span class="kt">double</span> <span class="n">box_length</span><span class="p">,</span> <span class="kt">int</span> <span class="n">i_particle</span><span class="p">,</span> <span class="kt">double</span> <span class="n">cutoff2</span><span class="p">,</span> <span class="n">MPI_Comm</span> <span class="n">comm</span><span class="p">)</span> <span class="p">{</span>
</code></pre></div></div>

<p>Now update the two times <code class="language-plaintext highlighter-rouge">get_particle_energy()</code> is called by <code class="language-plaintext highlighter-rouge">main</code>:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="kt">double</span> <span class="n">current_energy</span> <span class="o">=</span> <span class="n">get_particle_energy</span><span class="p">(</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">num_particles</span><span class="p">,</span> <span class="n">box_length</span><span class="p">,</span> <span class="n">i_particle</span><span class="p">,</span> <span class="n">simulation_cutoff2</span><span class="p">,</span> <span class="n">world_comm</span> <span class="p">);</span>
    <span class="p">...</span>
    <span class="kt">double</span> <span class="n">proposed_energy</span> <span class="o">=</span> <span class="n">get_particle_energy</span><span class="p">(</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">num_particles</span><span class="p">,</span> <span class="n">box_length</span><span class="p">,</span> <span class="n">i_particle</span><span class="p">,</span> <span class="n">simulation_cutoff2</span><span class="p">,</span> <span class="n">world_comm</span> <span class="p">);</span>
</code></pre></div></div>

<p>Place the following at the beginning of <code class="language-plaintext highlighter-rouge">get_particle_energy()</code>:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Get information about the MPI communicator</span>
  <span class="kt">int</span> <span class="n">my_rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">;</span>
  <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">world_size</span><span class="p">);</span>
  <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">comm</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">my_rank</span><span class="p">);</span>
</code></pre></div></div>

<p>Change the <code class="language-plaintext highlighter-rouge">for</code> loop in <code class="language-plaintext highlighter-rouge">get_particle_energy</code> to the following:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j_particle</span><span class="o">=</span><span class="n">my_rank</span><span class="p">;</span> <span class="n">j_particle</span> <span class="o">&lt;</span> <span class="n">particle_count</span><span class="p">;</span> <span class="n">j_particle</span> <span class="o">+=</span> <span class="n">world_size</span><span class="p">)</span> <span class="p">{</span>
</code></pre></div></div>

<p>The above code will cause each rank to iterate over particles with a stride of <code class="language-plaintext highlighter-rouge">world_size</code> and an initial offset of <code class="language-plaintext highlighter-rouge">my_rank</code>.
For example, if you run on 4 ranks, rank 0 will iterate over particles 
0, 4, 8, 12, etc., while rank 1 will iterate over particles 1, 5, 9, 13,
 etc.</p>

<p>We then need to sum the energies across all ranks.
Replace the line <code class="language-plaintext highlighter-rouge">return e_total;</code> with the following:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Sum the energy across all ranks</span>
  <span class="kt">double</span> <span class="n">e_summed</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span>
  <span class="n">MPI_Reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="n">e_total</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">e_summed</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="n">MPI_SUM</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">comm</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">e_summed</span><span class="p">;</span>
</code></pre></div></div>

<p>Try to run it in parallel now:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./mc
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>16000   -2.19516e+19
17000   -2.19517e+19

===================================================================================
=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES
=   PID 81043 RUNNING AT Taylors-MacBook-Pro.local
=   EXIT CODE: 9
=   CLEANING UP REMAINING PROCESSES
=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES
===================================================================================
YOUR APPLICATION TERMINATED WITH THE EXIT STRING: Segmentation fault: 11 (signal 11)
This typically refers to a problem with your application.
Please see the FAQ page for debugging suggestions
</code></pre></div></div>

<p>That doesn’t seem right at all.
What went wrong?</p>

<p>Our call to <code class="language-plaintext highlighter-rouge">MPI_Reduce</code> causes the energies to be summed onto rank 0, but none of the other ranks have the summed energies.
To have the energies reduced to all of the ranks, replace the <code class="language-plaintext highlighter-rouge">MPI_Reduce</code> call with a call to <code class="language-plaintext highlighter-rouge">MPI_Allreduce</code>:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">MPI_Allreduce</span><span class="p">(</span><span class="o">&amp;</span><span class="n">e_total</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">e_summed</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="n">MPI_SUM</span><span class="p">,</span> <span class="n">comm</span><span class="p">);</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./mc
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>497000   -6.28644
498000   -6.2899
499000   -5.96744
500000   -6.06862
Total simulation time: 8.38658
    Energy time:       8.24201
    Decision time:     0.0563176
</code></pre></div></div>

<p>This is better, but we certainly aren’t getting good timings.</p>

<p>Before we work on the timings problem, let’s try another experiment.
Near the top of <code class="language-plaintext highlighter-rouge">mc.cpp</code> is some code that initializes the random number generator with a random seed.
Currently, the random number generator is being initialized with a fixed random seed of <code class="language-plaintext highlighter-rouge">1</code>:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Initialize the random number generator with a pre-defined seed</span>
<span class="n">std</span><span class="o">::</span><span class="n">mt19937</span> <span class="nf">mt</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="c1">// Initialize the random number generator with a random seed</span>
<span class="c1">//std::random_device rd;</span>
<span class="c1">//std::mt19937 mt(rd());</span>
</code></pre></div></div>

<p>Let’s try switching to using a random number to initialize the random number generator:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Initialize the random number generator with a pre-defined seed</span>
<span class="c1">//std::mt19937 mt(1);</span>

<span class="c1">// Initialize the random number generator with a random seed</span>
<span class="n">std</span><span class="o">::</span><span class="n">random_device</span> <span class="n">rd</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">mt19937</span> <span class="nf">mt</span><span class="p">(</span><span class="n">rd</span><span class="p">());</span>
</code></pre></div></div>

<p>Now recompile and run again:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./mc
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>497000   -7.9279e+12
498000   -7.9279e+12
499000   -7.9279e+12
500000   -7.9279e+12
Total simulation time: 8.73895
    Energy time:       8.59179
    Decision time:     0.0549728
</code></pre></div></div>

<p>These are some crazy, unphysical numbers!
If you try running again with a single process (<code class="language-plaintext highlighter-rouge">mpiexec -n 1 ./mc</code>),
 you can confirm that the code gives much more reasonable energies when 
running on in serial.
The problem is that each iteration, the coordinates are updated by 
randomly displacing one of the particles.
Each rank randomly selects a particle to displace and the displacement 
vector.
Instead of contributing to the calculation of the same particle’s 
interaction energies for the same nuclear configuration, each rank ends 
up calculating some of the interaction energies for different atoms and 
different coordinates.
This leads to utter chaos throughout the simulation.</p>

<p>You might be tempted to fix this by generating the random number 
generator seed on a single process, and then sending that information to
 the other processes, so that every process is using the same seed.
Although that might sound reasonable, it would still leave open the 
possibility that different processes could end up diverging over the 
course of a long simulation (remember, computers aren’t infinitely 
accurate - slight descrepancies are guaranteed to happen, given enough 
time).</p>

<p>To fix this, we will have rank 0 be the only rank that randomly selects a particle or a displacement vector.
Rank 0 will then broadcast all necessary information to the other ranks, so that they keep in sync.</p>

<p>Replace the line where the coordinates are intially generated (where <code class="language-plaintext highlighter-rouge">generate_initial_state</code> is called) with this:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">if</span> <span class="p">(</span> <span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="n">generate_initial_state</span><span class="p">(</span><span class="n">num_particles</span><span class="p">,</span> <span class="n">box_length</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="n">MPI_Bcast</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">num_particles</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">world_comm</span><span class="p">);</span>
</code></pre></div></div>

<p>At the beginning of the <code class="language-plaintext highlighter-rouge">for</code> loop in <code class="language-plaintext highlighter-rouge">main</code> you will see the following code:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Beginning of main MC iterative loop</span>
  <span class="n">n_trials</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i_step</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i_step</span><span class="o">&lt;</span><span class="n">n_steps</span><span class="p">;</span> <span class="n">i_step</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">n_trials</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">i_particle</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span> <span class="kt">double</span><span class="p">(</span><span class="n">num_particles</span><span class="p">)</span> <span class="o">*</span> <span class="n">dist</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span> <span class="p">);</span>
    <span class="kt">double</span> <span class="n">random_displacement</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">random_displacement</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span> <span class="p">(</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">dist</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span> <span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span> <span class="p">)</span> <span class="o">*</span> <span class="n">max_displacement</span><span class="p">;</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>Replace the above with the following:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Beginning of main MC iterative loop</span>
  <span class="n">n_trials</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i_step</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i_step</span><span class="o">&lt;</span><span class="n">n_steps</span><span class="p">;</span> <span class="n">i_step</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>

    <span class="kt">int</span> <span class="n">i_particle</span><span class="p">;</span>
    <span class="kt">double</span> <span class="n">random_displacement</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
    <span class="k">if</span> <span class="p">(</span> <span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
      <span class="n">n_trials</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
      <span class="n">i_particle</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span> <span class="kt">double</span><span class="p">(</span><span class="n">num_particles</span><span class="p">)</span> <span class="o">*</span> <span class="n">dist</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span> <span class="p">);</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">random_displacement</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span> <span class="p">(</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">dist</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span> <span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span> <span class="p">)</span> <span class="o">*</span> <span class="n">max_displacement</span><span class="p">;</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">MPI_Bcast</span><span class="p">(</span><span class="o">&amp;</span><span class="n">i_particle</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">world_comm</span><span class="p">);</span>
    <span class="n">MPI_Bcast</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">num_particles</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">world_comm</span><span class="p">);</span>
    <span class="n">MPI_Bcast</span><span class="p">(</span><span class="n">random_displacement</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">MPI_DOUBLE</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">world_comm</span><span class="p">);</span>
</code></pre></div></div>

<p>At the end of the <code class="language-plaintext highlighter-rouge">for</code> loop in <code class="language-plaintext highlighter-rouge">main</code> is the following code:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1">// test whether to accept or reject this step</span>
    <span class="kt">double</span> <span class="n">start_decision_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
    <span class="kt">double</span> <span class="n">delta_e</span> <span class="o">=</span> <span class="n">proposed_energy</span> <span class="o">-</span> <span class="n">current_energy</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">accept</span> <span class="o">=</span> <span class="n">accept_or_reject</span><span class="p">(</span><span class="n">delta_e</span><span class="p">,</span> <span class="n">beta</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">accept</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">total_pair_energy</span> <span class="o">+=</span> <span class="n">delta_e</span><span class="p">;</span>
      <span class="n">n_accept</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">else</span> <span class="p">{</span>
      <span class="c1">// revert the position of the test particle</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">coordinates</span><span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="n">i_particle</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">random_displacement</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
        <span class="n">coordinates</span><span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="n">i_particle</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">box_length</span> <span class="o">*</span> <span class="n">round</span><span class="p">(</span><span class="n">coordinates</span><span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="n">i_particle</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">box_length</span><span class="p">);</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="kt">double</span> <span class="n">total_energy</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_pair_energy</span> <span class="o">+</span> <span class="n">tail_correction</span><span class="p">)</span> <span class="o">/</span> <span class="kt">double</span><span class="p">(</span><span class="n">num_particles</span><span class="p">);</span>
    <span class="n">energy_array</span><span class="p">[</span><span class="n">i_step</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_energy</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span> <span class="p">(</span><span class="n">i_step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">freq</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
      <span class="k">if</span> <span class="p">(</span> <span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">i_step</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="s">"   "</span> <span class="o">&lt;&lt;</span> <span class="n">energy_array</span><span class="p">[</span><span class="n">i_step</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
      <span class="p">}</span>

      <span class="k">if</span> <span class="p">(</span> <span class="n">tune_displacement</span> <span class="p">)</span> <span class="p">{</span>
        <span class="n">max_displacement</span> <span class="o">=</span> <span class="n">adjust_displacement</span><span class="p">(</span><span class="n">n_trials</span><span class="p">,</span> <span class="n">n_accept</span><span class="p">,</span> <span class="n">max_displacement</span><span class="p">);</span>
        <span class="n">n_trials</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="n">n_accept</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
      <span class="p">}</span>

      <span class="n">total_decision_time</span> <span class="o">+=</span> <span class="n">MPI_Wtime</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_decision_time</span><span class="p">;</span>
</code></pre></div></div>

<p>Replace the above with the following, so that only rank <code class="language-plaintext highlighter-rouge">0</code> is executing it:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">if</span> <span class="p">(</span> <span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
      <span class="c1">// test whether to accept or reject this step</span>
      <span class="kt">double</span> <span class="n">start_decision_time</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>
      <span class="kt">double</span> <span class="n">delta_e</span> <span class="o">=</span> <span class="n">proposed_energy</span> <span class="o">-</span> <span class="n">current_energy</span><span class="p">;</span>
      <span class="kt">bool</span> <span class="n">accept</span> <span class="o">=</span> <span class="n">accept_or_reject</span><span class="p">(</span><span class="n">delta_e</span><span class="p">,</span> <span class="n">beta</span><span class="p">);</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">accept</span><span class="p">)</span> <span class="p">{</span>
	<span class="n">total_pair_energy</span> <span class="o">+=</span> <span class="n">delta_e</span><span class="p">;</span>
	<span class="n">n_accept</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
      <span class="p">}</span>
      <span class="k">else</span> <span class="p">{</span>
	<span class="c1">// revert the position of the test particle</span>
	<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
	  <span class="n">coordinates</span><span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="n">i_particle</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">random_displacement</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
	  <span class="n">coordinates</span><span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="n">i_particle</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">box_length</span> <span class="o">*</span> <span class="n">round</span><span class="p">(</span><span class="n">coordinates</span><span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="n">i_particle</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">box_length</span><span class="p">);</span>
	<span class="p">}</span>
      <span class="p">}</span>

      <span class="kt">double</span> <span class="n">total_energy</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_pair_energy</span> <span class="o">+</span> <span class="n">tail_correction</span><span class="p">)</span> <span class="o">/</span> <span class="kt">double</span><span class="p">(</span><span class="n">num_particles</span><span class="p">);</span>
      <span class="n">energy_array</span><span class="p">[</span><span class="n">i_step</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_energy</span><span class="p">;</span>

      <span class="k">if</span> <span class="p">(</span> <span class="p">(</span><span class="n">i_step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">freq</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
	<span class="k">if</span> <span class="p">(</span> <span class="n">my_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
	  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">i_step</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="s">"   "</span> <span class="o">&lt;&lt;</span> <span class="n">energy_array</span><span class="p">[</span><span class="n">i_step</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
	<span class="p">}</span>

	<span class="k">if</span> <span class="p">(</span> <span class="n">tune_displacement</span> <span class="p">)</span> <span class="p">{</span>
	  <span class="n">max_displacement</span> <span class="o">=</span> <span class="n">adjust_displacement</span><span class="p">(</span><span class="n">n_trials</span><span class="p">,</span> <span class="n">n_accept</span><span class="p">,</span> <span class="n">max_displacement</span><span class="p">);</span>
	  <span class="n">n_trials</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	  <span class="n">n_accept</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="p">}</span>
      <span class="p">}</span>

      <span class="n">total_decision_time</span> <span class="o">+=</span> <span class="n">MPI_Wtime</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_decision_time</span><span class="p">;</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>Recompile and rerun the code.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./mc
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>497000   -6.06666
498000   -6.10058
499000   -5.98052
500000   -5.95301
Total simulation time: 16.7881
    Energy time:       15.9948
    Decision time:     0.0690625
</code></pre></div></div>

<p>This time the energies are much more consistent with what we expect; 
however, our timings are considerably worse than when we were only 
running on single process!
This is because the system we are running these calculations on is 
extremely small.
If you check the system parameters (under the <code class="language-plaintext highlighter-rouge">Parameter setup</code> comment in <code class="language-plaintext highlighter-rouge">mc.cpp</code>), you will see that this calculation only involves 100 particles.
The amount of work required to compute the energy of <code class="language-plaintext highlighter-rouge">100</code> Lennard-Jones particles is actually smaller than the amount of overhead associated with the extra MPI processes.
Let’s make the simulation somewhat larger:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kt">int</span> <span class="n">n_steps</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">freq</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">num_particles</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">;</span>
</code></pre></div></div>

<p>Recompile and rerun the code on a single core.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
<span class="nv">$ </span>./mc
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>97000   612.067
98000   609.113
99000   603.538
100000   599.461
Total simulation time: 41.0191
    Energy time:       39.9748
    Decision time:     0.011933
</code></pre></div></div>

<p>Finally, run the calculation in parallel.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>mpiexec <span class="nt">-n</span> 4 ./mc
</code></pre></div></div>

<div class="language-plaintext output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>97000   99.1126
98000   93.454
99000   91.1246
100000   87.397
Total simulation time: 22.2873
    Energy time:       15.4661
    Decision time:     0.0175401
</code></pre></div></div>

<p>Now we can clearly see a speedup when running in parallel.</p>



<blockquote class="keypoints">
  <h2>Key Points</h2>
  <ul>
    
    <li><p>Where possible, use collective communication operations 
instead of point-to-point communication for improved efficiency and 
simplicity.</p>
</li>
    
    <li><p>Intelligent design choices can help you reduce the memory footprint required by MPI-parallelized codes</p>
</li>
    
  </ul>
</blockquote>

</article>
















<div class="row">
  <div class="col-xs-1">
    <h3 class="text-left">
      
      <a href="https://education.molssi.org/parallel-programming/03-distributed-examples-mpi4py/index.html"><span class="glyphicon glyphicon-menu-left" aria-hidden="true"></span><span class="sr-only">previous episode</span></a>
      
    </h3>
  </div>
  <div class="col-xs-10">
    
  </div>
  <div class="col-xs-1">
    <h3 class="text-right">
      
      <a href="https://education.molssi.org/parallel-programming/05-shared-intro/index.html"><span class="glyphicon glyphicon-menu-right" aria-hidden="true"></span><span class="sr-only">next episode</span></a>
      
    </h3>
  </div>
</div>


      
      
<footer>
  <div class="row">
    <div class="col-md-6 copyright" align="left">
        Copyright © 2018–2021
	<a href="http://molssi.org/">The Molecular Sciences Software Institute</a>
    </div>
    <div class="col-md-6 help-links" align="right">
	
	<a href="https://github.com/MolSSI-Education/parallel-programming/edit/gh-pages/_episodes/04-distributed-examples.md">Edit on GitHub</a>
	
	/
	<a href="https://github.com/MolSSI-Education/parallel-programming/blob/gh-pages/CONTRIBUTING.md">Contributing</a>
	/
	<a href="https://github.com/MolSSI-Education/parallel-programming/">Source</a>
	/
	<a href="https://github.com/MolSSI-Education/parallel-programming/blob/gh-pages/CITATION">Cite</a>
	/
	<a href="mailto:education@molssi.org">Contact</a>
    </div>
  </div>
  <div class="row">
    <div class="col-md-12" align="center">
      Using <a href="https://github.com/carpentries/styles/">The Carpentries style</a>
      version <a href="https://github.com/carpentries/styles/releases/tag/v9.5.0">9.5.0</a>.
    </div>
  </div>
</footer>

      
    </div>
    
<script src="Parallel%20Programming%20MPI%20Hands-On%20-%20C++_fichiers/jquery.min.js"></script>
<script src="Parallel%20Programming%20MPI%20Hands-On%20-%20C++_fichiers/bootstrap.min.js"></script>
<script src="Parallel%20Programming%20MPI%20Hands-On%20-%20C++_fichiers/lesson.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="Parallel%20Programming%20MPI%20Hands-On%20-%20C++_fichiers/google-analytics_analytics.js"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-169902961-1');
</script>


  

</body></html>